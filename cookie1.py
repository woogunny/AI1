# -*- coding: utf-8 -*-
"""cookie.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OELL4W4Eg-EW9S-7pANVE7oF-x17m5eS
"""

pwd

pip install numpy

pip install pandas

pip argparse

pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0

pip list

pip install seaborn

pip install tensorflow

pip install scikit-learn

pip install matplotlib

pip install opencv-python

pip install -U scikit-learn

!unzip -qq "/content/drive/MyDrive/dataset1.zip"

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import cv2
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F

from PIL import Image
from torchvision import transforms, models

from torch.utils.data import Dataset
from torchsummary import summary
from torch.utils.data import DataLoader
from torchvision.utils import make_grid

from sklearn.metrics import f1_score


# import argparse

#dataset

class ImageDataset(Dataset):
    def __init__(self, directory, transform=None):
        self.directory = directory
        self.transform = transform
        self.classes = sorted(os.listdir(directory))
        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}
        self.samples = []

        for class_name in self.classes:
            class_dir = os.path.join(self.directory, class_name)
            for image_name in os.listdir(class_dir):
                self.samples.append((os.path.join(class_dir, image_name), self.class_to_idx[class_name]))


    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        image_path, label = self.samples[idx]
        image = Image.open(image_path).convert('RGB')

        if self.transform:
            image = self.transform(image)
        return image, label

# model
def get_model(name, n_class, pretrained=False):
      if name == "vgg16":
          model = models.vgg16(pretrained=pretrained)
          num_features = model.classifier[6].in_features
          model.classifier[6] = nn.Linear(num_features, n_class)
      elif name == "resnet":
          model = models.resnet18(pretrained=pretrained)
          num_features = model.fc.in_features
          model.fc = nn.Linear(num_features, n_class)
      return model

class Simple2DCNN(nn.Module):
      def __init__(self):
          super(Simple2DCNN, self).__init__()
          self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
          self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
          self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
          self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)
          self.adaptive_pool = nn.AdaptiveAvgPool2d(10)
          self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
          self.relu = nn.ReLU()
          self.fc = nn.Linear(256*10*10, 3)  # Adaptive Pooling 이후의 출력 크기에 맞춰 조정

      def forward(self, x):
          x = self.pool(F.relu(self.conv1(x)))
          x = self.pool(F.relu(self.conv2(x)))
          x = self.pool(F.relu(self.conv3(x)))
          x = self.relu(self.conv4(x))
          x = self.adaptive_pool(x)
          x = x.view(-1, 256*10*10)  # 적절한 크기로 플래트닝
          x = self.fc(x)
          return x

#utils

def visualize_batch(data_loader, class_names):
    images, labels = next(iter(data_loader))
    img_grid =make_grid(images, nrow=8)
    npimg=img_grid.numpy()

    plt.figure(figsize=(20,10))
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.title('Dataset Visualization')

    labels=[class_names[label] for label in labels]
    for i, label in enumerate(labels):

        x= (i%8 + 0.5) /8
        y= (i // 8)/ (len(labels) / 8)
        plt.text(x, y, label, ha='center', va='bottom', transform=plt.gca().transAxes, color='white')

    plt.axis('off')
    plt.show()

#train
from torch.optim.lr_scheduler import MultiStepLR, StepLR

def train_model(model, train_loader, val_loader, epochs, device):
    model.to(device)
    criterion = nn.CrossEntropyLoss()
    # criterion = nn.BCEWithLogitsLoss()
    # criterion = nn.SoftMarginLoss()
    # criterion = nn.MultiMarginLoss()
    # criterion = nn.MSELoss(size_average=None, reduce=None, reduction='mean')
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001)
    # scheduler = MultiStepLR(optimizer, [5,10],gamma=0.1)
    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)

    # 성능 기록 초기화
    best_score = 0
    best_model = None

    loss_history = []
    val_loss_history = []
    accuracy_history = []
    val_accuracy_history = []

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        train_loss = []
        total_batches = len(train_loader)
        correct_predictions = 0
        total_predictions = 0

        for i, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss =+ loss.item()
            train_loss.append(loss.item()) # loss.item()은 현재 배치에 대한 손실 값을 파이썬의 floate 타입으로 변환.
            # 훈련 과정에서 각 배치를 처리할 때마다 이 줄이 실행되어, 각 배치의 손실 값을 train_loss 리스트에 순차적으로 추가

            _, predicted = torch.max(outputs, 1)
            total_predictions += labels.size(0)
            correct_predictions += (predicted == labels).sum().item()


        avg_loss = running_loss / len(train_loader)
        accuracy = 100 * correct_predictions / total_predictions
        loss_history.append(avg_loss)
        accuracy_history.append(accuracy)
        _val_loss, _val_score, _val_accuracy = validation(model, criterion, val_loader, device)
        val_loss_history.append(_val_loss)
        val_accuracy_history.append(_val_accuracy)
        _train_loss = np.mean(train_loss) # 각 배치에서 계산된 모든 손실 값의 평균을 구함

        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%, \t Val Loss : {_val_loss:.5f} Val Accuracy : {_val_accuracy:.2f}% Val F1 Score : {_val_score:.5f}")

        # scheduler이 설정되어 있다면 검증 성능에 따라 학습률을 조정
        # if scheduler is not None:
        scheduler.step()

    print("Finished Training")

    plt.figure(figsize=(10, 5))
    plt.plot(range(1, epochs+1), loss_history, label='Avg Loss per Epoch')
    plt.plot(range(1, epochs+1), val_loss_history, label='Val_Avg Loss per Epoch')
    plt.title('Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Average Loss')
    plt.legend()
    plt.show()

    plt.figure(figsize=(10, 5))
    plt.plot(range(1, epochs+1), accuracy_history, label='Accuracy per Epoch')
    plt.plot(range(1, epochs+1), val_accuracy_history, label='val_Accuracy per Epoch')
    plt.title('Training Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.show()

    torch.save(model.state_dict(), f"./simple_weight_steplr_2d.pth")

    #     # 가장 좋은 성능을 보인 모델을 반환
    #     if best_score < _val_score:
    #         best_score = _val_score
    #         best_model = model

    # return best_model




def validation(model, criterion, val_loader, device):
    model.eval() # 평가모드
    val_loss = []
    preds, true_labels = [], []
    correct_predictions = 0
    total_predictions = 0

    # 평가모드의 경우에는 gradient를 초기화하는 부분이 없음 (backward 필요없음. 오직 평가만!)
    with torch.no_grad(): # 이 블록 내에서 그레디언트 계산을 중단하여, 필요하지 않은 메모리 사용을 줄이고 계산 속도 향상.
        for imgs, labels in iter(val_loader):
            imgs = imgs.float().to(device)
            labels = labels.long().to(device)  # 데이터 타입 long으로 변경한 후 device로 올림 (int로 변경하였을 때, error 발생했음)

            pred = model(imgs)

            loss = criterion(pred, labels)

            # pred는 모델이 반환한 예측값. 각 클래스에 대한 확률 또는 점수를 포함하는 텐서. argmax(1)은 각 샘플에 대해 가장 높은 점수를 가진 클래스의 인덱스를 찾아줌.
            # detach()는 현재 계산 그래프로부터 이 텐서를 분리하여, 이후 연산이 그래프에 기록되지 않도록함. 메모리 사용량 줄임
            # cpu()는 cpu로 옮김 (GPU에 있었다면)
            # numpy()는 텐서를 numpy 배열로 변환
            # tolist()는 numpy 배열을 파이썬 리스트로 변환
            preds += pred.argmax(1).detach().cpu().numpy().tolist()

            _, predicted = torch.max(pred, 1)
            total_predictions += labels.size(0)
            correct_predictions += (predicted == labels).sum().item()

            # 실제 라벨도 위와 동일한 과정 진행
            true_labels += labels.detach().cpu().numpy().tolist()

            val_loss.append(loss.item())

        _val_accuracy = 100 * correct_predictions / total_predictions

        _val_loss = np.mean(val_loss)
        # average = 'macro'는 F1점수를 계산할 때, 각 클래스에 대한 F1점수를 동일한 가중치로 평균내어 전체 클래스에 대한 평균 F1점수를 계산.
        # 각 클래스의 샘플 크기와 관계없이 모든 클래스를 동등하게 취급. 이는 클래스 불균형이 있을 때 유용하며, 모든 클래스를 공평하게 평가하고자 할 때 사용.
        _val_score = f1_score(true_labels, preds, average='macro')

    return _val_loss, _val_score, _val_accuracy

#evaluate

def evaluate_model(model, test_loader, device):

    # 모델 가중치 로드
    model.load_state_dict(torch.load("simple_weight_steplr_2d.pth", map_location=device))


    model.eval()

    criterion = nn.CrossEntropyLoss()

    total = 0
    correct = 0
    total_loss = 0.0

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)

            loss = criterion(outputs, labels)

            total_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)

            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = total_loss / len(test_loader)

    accuracy = correct / total * 100

    print(f'Test Accuracy: {accuracy:.2f}%, Avg Loss: {avg_loss:.4f}')


    return accuracy, avg_loss

#main()

# from augment import*
# from evaluate import*

def main():


  print("Start Code")
  print("My model")

  model = Simple2DCNN()

#   model = get_model('resnet', 3, pretrained=False)

  summary(model.cuda(), (3,224,224))


  transform = transforms.Compose([
            transforms.Resize((224,224)),
            transforms.ToTensor(),
  ])
  train_dataset = ImageDataset(directory='/content/train/',transform=transform)
  val_dataset = ImageDataset(directory='/content/validation/',transform=transform)
  test_dataset = ImageDataset(directory='/content/test/',transform=transform)

  train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
  val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)
  test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

#   dataiter = iter(train_loader)
#   data_loader, labels = next(iter(train_loader))
#   visualize_batch(data_loader, labels)

  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

  train_model(model, train_loader, val_loader, epochs=100, device=device)
  evaluate_model(model, test_loader, device=device)

main()

rm /content/validation/.DS_Store

rm /content/train/.DS_Store

rm /content/test/.DS_Store

rm /content/train/normal/.DS_Store

rm /content/train/benign/.DS_Store

rm /content/train/malignant/.DS_Store

rm /content/validation/normal/.DS_Store

rm /content/validation/benign/.DS_Store

rm /content/validation/malignant/.DS_Store
